---
title: "Clean GAD data for all waves. Save a seperate RAMP baseline data for CFA in addition to all wave for GMM"
author: "K L Purves"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: false
    number_sections: false
    highlight: monochrome
    theme: cerulean
code_folding: show

html_notebook:
  theme: cerulean
toc: yes
---

# Setup

```{r}
# clear global environment
remove(list = ls())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment=NA,
                      prompt=FALSE,
                      cache=FALSE)
```

Note: load tidyverse last!
```{r Load packages}
if(!require(summarytools)){
  install.packages("summarytools")
  library(summarytools)
}
if(!require(ggplot2)){
  install.packages("ggplot2")
  library(ggplot2)
}

if(!require(psych)){
  install.packages("psych")
  library(psych)
}

if(!require(tidyverse)){
  install.packages("tidyverse")
  library(tidyverse)
}

if(!require(kableExtra)){
  install.packages("kableExtra")
  library(kableExtra)
}


if(!require(multiplex)){
  install.packages("multiplex")
  library(multiplex)
}

if(!require(modeest)){
  install.packages("modeest")
  library(modeest)
}
```

```{r}
# read in the files (save to environment)

source("../../../Credentials/paths_anhedonia_analysis.R")
```

## read in all functions from function library

```{r call in function library functions}
# source all functions in the function library folder
files.sources = paste0("../functions/",list.files("../functions"))
sapply(files.sources, source)

```

# COPING data preprocessing {.tabset}

## read in and rename

### COPING Baseline
```{r}
# Read in the data

COPING_EDGI <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_edgi/gad7_coping_edgi.rds"))
COPING_GLAD <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_glad/gad7_coping_glad.rds"))
COPING_NBR <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_nbr/gad7_coping_nbr.rds"))

# merge GLAD, EDGI and NBR

COPING_baseline <- left_join(COPING_NBR, COPING_GLAD)
COPING_baseline <- left_join(COPING_baseline, COPING_EDGI)
  
# Check column names
COPING_baseline %>%
  colnames()

# Check dimensions
COPING_baseline %>%
  dim()

# Look at top rows of the data frame
COPING_baseline %>% 
  head()
```

Select & rename relevant columns (will be a function at some point)
```{r}

COPING_baseline.id <- COPING_baseline %>% #new dataset with ID
  drop_na(subjectid) %>% # Drop NAs
  select(-gad7.feeling_nervous_anxious_or_on_edge.1,
         -gad7.control_worrying_stop.1,
         -gad7.worrying_too_much_about_different_things.1,
         -gad7.trouble_relaxing.1,
         -gad7.sit_restless_hard.1,
         -gad7.becoming_easily_annoyed_or_irritable.1,
         -gad7.feeling_afraid_awful_happen.1,
         -gad7.awful_feeling_afraid_happen.1,
         -gad7.pandemic_feelings_felt,
         -gad7.care_difficult_home_things,
         -gad7.problems_made_care_difficult,
         -gad7.problems_made_difficult_care,
         -externalDataReference,
         ID = subjectid, # ID
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad7.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad7.control_worrying_stop,
         gad7.pandemic_worry_too_much = gad7.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad7.trouble_relaxing,
         gad7.pandemic_restless = gad7.sit_restless_hard,
         gad7.pandemic_easily_annoyed = gad7.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad7.awful_feeling_afraid_happen)


# Inspect colnames
colnames(COPING_baseline.id)

```



### COPING follow up A

```{r Read in COPING follow up A data}
# Read in the data
COPING_followupA <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_followupa/gad_coping_followupa.rds"))

  # Check column names
COPING_followupA %>%
  colnames()

# Check dimensions
COPING_followupA %>%
  dim()

# Look at top rows of the data frame
COPING_followupA %>% 
  head()
```

```{r}


COPING_followupA.id <- COPING_followupA %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop NAs
  add_column(sample = "COPING_followupA", .after = "externalDataReference") %>% #create new column 
  select(-gad.difficult_daily_life_issues,
         ID = externalDataReference, # ID
         sample,
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad.control_worrying_stop,
         gad7.pandemic_worry_too_much = gad.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad.trouble_relaxing,
         gad7.pandemic_restless = gad.sit_hard_restless,
         gad7.pandemic_easily_annoyed = gad.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad.awful_happen_feeling_afraid)

# Inspect colnames
colnames(COPING_followupA.id)

```
  
### COPING follow up B

```{r Read in COPING follow up B data}
# Read in the data
COPING_followupB <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_followupb/gad_coping_followupb.rds"))

# Check column names
COPING_followupB %>%
  colnames()

# Check dimensions
COPING_followupB %>%
  dim()

# Look at top rows of the data frame
COPING_followupB %>% 
  head()
```

Select & rename relevant columns (will be a function at some point)
```{r}


COPING_followupB.id <- COPING_followupB %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop NAs
  add_column(sample = "COPING_followupB", .after = "externalDataReference") %>% #create new column 
  select(-gad.difficult_daily_life_issues,
         ID = externalDataReference, # ID
         sample,
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad.stop_control_worrying,
         gad7.pandemic_worry_too_much = gad.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad.trouble_relaxing,
         gad7.pandemic_restless = gad.hard_sit_restless,
         gad7.pandemic_easily_annoyed = gad.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad.awful_feeling_afraid_happen)


# Inspect colnames
colnames(COPING_followupB.id)

```

### COPING followup A ongoing
```{r}
# Read in the data
COPING_followupA_ong <- readRDS(file = paste0(ilovedata, "/data_raw/2021-05-20/coping_followupa_ongoing/gad_coping_followupa_ongoing.rds"))

# Check column names
COPING_followupA_ong %>%
  colnames()

# Check dimensions
COPING_followupA_ong %>%
  dim()

# Look at top rows of the data frame
COPING_followupA_ong %>% 
  head()
```

Select & rename relevant columns (will be a function at some point)
```{r}

COPING_followupA_ong.id <- COPING_followupA_ong %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop NAs

  add_column(sample = "COPING_followupA_ong", .after = "externalDataReference") %>% #create new column 
  select(-gad.difficult_daily_life_issues,
         ID = externalDataReference, # ID
         sample,
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad.control_worrying_stop,
         gad7.pandemic_worry_too_much = gad.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad.trouble_relaxing,
         gad7.pandemic_restless = gad.sit_hard_restless,
         gad7.pandemic_easily_annoyed = gad.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad.awful_feeling_afraid_happen)


# Inspect colnames
colnames(COPING_followupA_ong.id)

```

## Join COPING follow up A and follow up A ongoing

```{r Join COPING follow up A and COPING follow up A ongoing, eval=FALSE}
# check column names match
colnames(COPING_followupA.id)
colnames(COPING_followupA_ong.id)

# rbind
COPING_followupA.id_joined <- rbind(COPING_followupA.id,
                                    COPING_followupA_ong.id)

dim(COPING_followupA.id_joined)
```

## Creating follow up time points

### Create waves within the FOLLOW UP DATA 
Note: dates from google sheet from Kirstin
Checked with Gerome - set start date as the date the survey was released, and keep window open until the DAY BEFORE the next survey was released

NOTE: Am changing wave indicators to be in order

For those who did an earlier wave during the time frame of a later wave, I include them in the later wave.

Include RAMP waves in ordering, even though COPING waves started later. So some earlier waves will only be RAMP


```{r}

# April/May (wave 1) - FOLLOW UP A
ramp_start1 <- as.POSIXct("2020-04-21")
ramp_end1 <-  as.POSIXct("2020-05-04")  

# May (wave 2) - FOLLOW UP B
ramp_start2 <- as.POSIXct("2020-05-05")
ramp_end2<-  as.POSIXct("2020-05-18")  


# MAY 2 (wave 3) - FOLLOW UP A
start1 <- as.POSIXct("2020-05-19")
end1 <-  as.POSIXct("2020-06-01")  

# JUNE 1 (wave 4) - FOLLOW UP B
start2 <- as.POSIXct("2020-06-02")
end2<-  as.POSIXct("2020-06-15")  

# JUNE 2 (wave 5) - FOLLOW UP A
start3 <- as.POSIXct("2020-06-16")
end3 <-  as.POSIXct("2020-06-29") 

# JULY 1 (wave 6) - FOLLOW UP B
start4 <- as.POSIXct("2020-06-30")
end4<-  as.POSIXct("2020-07-13") 

# JULY 2 (wave 7) - FOLLOW UP A
start5 <- as.POSIXct("2020-07-14")
end5 <-  as.POSIXct("2020-07-27") ## Ongoing starts from here?

# JULY - AUG (wave 8) - FOLLOW UP B
start6 <- as.POSIXct("2020-07-28") 
end6 <-  as.POSIXct("2020-08-24") 

# AUG - SEPT (wave 9) - FOLLOW UP A
start7 <- as.POSIXct("2020-08-25")
end7 <-  as.POSIXct("2020-09-21") 

# SEPT - OCT (wave 10) - FOLLOW UP B
start8 <- as.POSIXct("2020-09-22")
end8 <-  as.POSIXct("2020-10-19") 

# OCT - NOV (wave 11) - FOLLOW UP A
start9 <- as.POSIXct("2020-10-20")
end9 <-  as.POSIXct("2020-11-16") 

# NOV - DEC (wave 12) - FOLLOW UP B
start10 <- as.POSIXct("2020-11-17")
end10 <-  as.POSIXct("2020-12-14") 

# DEC - JAN (wave 13) - FOLLOW UP A
start11 <- as.POSIXct("2020-12-15")
end11 <-  as.POSIXct("2021-01-11") 

# JAN - FEB (wave 14) - FOLLOW UP B
start12 <- as.POSIXct("2021-01-12")
end12 <-  as.POSIXct("2021-02-08") 

# FEB - MARCH (wave 15) - FOLLOW UP A
start13 <- as.POSIXct("2021-02-09")
end13 <-  as.POSIXct("2021-03-08") 

# MARCH - APR (wave 16) - FOLLOW UP B
start14 <- as.POSIXct("2021-03-09")
end14 <-  as.POSIXct("2021-04-05") 

# APR - MAY (wave 17) - FOLLOW UP A
start15 <- as.POSIXct("2021-04-06")
end15 <-  as.POSIXct("2021-05-03")

# MAY - JUNE (wave 18) - FOLLOW UP B
start16 <- as.POSIXct("2021-05-04")
end16 <-  as.POSIXct("2021-05-31")

# JUNE - JULY (wave 19) - FOLLOW UP A
start17 <- as.POSIXct("2021-06-01")
end17 <-  as.POSIXct("2021-06-28")

# JUNE - JULY (wave 20) - FOLLOW UP B
start18 <- as.POSIXct("2021-06-29")
end18 <-  as.POSIXct("2021-07-26")

# JUNE - JULY (wave 21) - FOLLOW UP A
start19 <- as.POSIXct("2021-07-27")
end19 <-  as.POSIXct("2021-08-17")

#JM**do we have data beyond this?


COPING_followupA.id <- COPING_followupA.id %>%
  mutate(waveA = case_when(startDate >= start1 & startDate < end1 ~ ".Wave_03",
                           startDate >= start2 & startDate <= end2 ~ ".Wave_04",
                            startDate >= start3 & startDate <= end3 ~ ".Wave_03", #repeat
                           startDate >= start4 & startDate <= end4 ~ ".Wave_06",
                            startDate >= start5 & startDate <= end5 ~ ".Wave_07",
                           startDate >= start6 & startDate <= end6 ~ ".Wave_08",
                            startDate >= start7 & startDate <= end7 ~ ".Wave_09",
                           startDate >= start8 & startDate <= end8 ~ ".Wave_10",
                            startDate >= start9 & startDate <= end9 ~ ".Wave_11",
                           startDate >= start10 & startDate <= end10 ~ ".Wave_12",
                            startDate >= start11 & startDate <= end11 ~ ".Wave_13",
                           startDate >= start12 & startDate <= end12 ~ ".Wave_14",
                            startDate >= start13 & startDate <= end13 ~ ".Wave_15",
                              startDate >= start14 & startDate <= end14 ~ ".Wave_16",
                            startDate >= start15 & startDate <= end15 ~ ".Wave_17",
                            startDate >= start16 & startDate <= end16 ~ ".Wave_18",
                           startDate >= start17 & startDate <= end17 ~ ".Wave_19",
                           startDate >= start18 & startDate <= end18 ~ ".Wave_20",
                            startDate >= start19 & startDate <= end19 ~ ".Wave_21"))

COPING_followupA_ong.id <- COPING_followupA_ong.id %>%
  mutate(waveA = case_when(startDate >= start1 & startDate < end1 ~ ".Wave_03",
                           startDate >= start2 & startDate <= end2 ~ ".Wave_04",
                            startDate >= start3 & startDate <= end3 ~ ".Wave_05",
                           startDate >= start4 & startDate <= end4 ~ ".Wave_06",
                            startDate >= start5 & startDate < start6 ~ ".Wave_07",
                           startDate >= start6 & startDate <= end6 ~ ".Wave_08",
                            startDate >= start7 & startDate <= end7 ~ ".Wave_09",
                           startDate >= start8 & startDate <= end8 ~ ".Wave_10",
                            startDate >= start9 & startDate <= end9 ~ ".Wave_11",
                           startDate >= start10 & startDate <= end10 ~ ".Wave_12",
                            startDate >= start11 & startDate <= end11 ~ ".Wave_13",
                           startDate >= start12 & startDate <= end12 ~ ".Wave_14",
                            startDate >= start13 & startDate <= end13 ~ ".Wave_15",
                              startDate >= start14 & startDate <= end14 ~ ".Wave_16",
                            startDate >= start15 & startDate <= end15 ~ ".Wave_17",
                            startDate >= start16 & startDate <= end16 ~ ".Wave_18",
                           startDate >= start17 & startDate <= end17 ~ ".Wave_19",
                           startDate >= start18 & startDate <= end18 ~ ".Wave_20",
                            startDate >= start19 & startDate <= end19 ~ ".Wave_21"))

COPING_followupB.id <- COPING_followupB.id %>%
  mutate(waveB = case_when(startDate >= start1 & startDate < end1 ~ ".Wave_3A_in_B", # should be impossible to exist
                           startDate >= start2 & startDate <= end2 ~ ".Wave_04",
                            startDate >= start3 & startDate <= end3 ~ ".Wave_05",
                           startDate >= start4 & startDate < start5 ~ ".Wave_06",
                            startDate >= start5 & startDate <= end5 ~ ".Wave_07",
                           startDate >= start6 & startDate <= end6 ~ ".Wave_08",
                            startDate >= start7 & startDate <= end7 ~ ".Wave_09",
                           startDate >= start8 & startDate <= end8 ~ ".Wave_10",
                            startDate >= start9 & startDate <= end9 ~ ".Wave_11",
                           startDate >= start10 & startDate <= end10 ~ ".Wave_12",
                            startDate >= start11 & startDate <= end11 ~ ".Wave_13",
                           startDate >= start12 & startDate <= end12 ~ ".Wave_14",
                            startDate >= start13 & startDate <= end13 ~ ".Wave_15",
                              startDate >= start14 & startDate <= end14 ~ ".Wave_16",
                            startDate >= start15 & startDate <= end15 ~ ".Wave_17",
                            startDate >= start16 & startDate <= end16 ~ ".Wave_18",
                           startDate >= start17 & startDate <= end17 ~ ".Wave_19",
                           startDate >= start18 & startDate <= end18 ~ ".Wave_20",
                            startDate >= start19 & startDate <= end19 ~ ".Wave_21"))

```

### check for number of entries per wave

```{r check for number of entries per wave COPING}
COPING_followupA.id %>%
  group_by(waveA) %>%
  count()

COPING_followupA_ong.id %>%
  group_by(waveA) %>%
  count()

COPING_followupB.id %>%
  group_by(waveB) %>%
  count()
```

### Identifying duplicate IDs in a single wave
```{r Identifying duplicate IDs in a single wave COPING}

##Identify dup IDs in a single wave (follow up A)
COPING_followupA.id %>%
   group_by(waveA, ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)


##Identify dup IDs in a single wave (follow up A ongoing)
COPING_followupA_ong.id %>%
   group_by(waveA, ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)


##Identify dup IDs in a single wave (B) 
COPING_followupB.id %>%
   group_by(waveB, ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)

##Identify dup IDs in baseline 
COPING_baseline.id %>%
   group_by(ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)


```

**removing duplicates, reatining the latest possible data where there are repeats**

### Want the LATER data entry from people who answered twice within a single wave 
We want there to be unique IDs within each of the waves
```{r}
##FOLLOW UP A
##confirm number of rows in current dataset (= 22542)
nrow(COPING_followupA.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
COPING_followupA.id <- COPING_followupA.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(waveA,
                      fromLast = TRUE)
           )

##confirm number of rows in dataset after filtering (should be 22485)
nrow(COPING_followupA.id)

##FOLLOW UP A ONGOING
##confirm number of rows in current dataset (= 22542)
nrow(COPING_followupA_ong.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
COPING_followupA_ong.id <- COPING_followupA_ong.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(waveA,
                      fromLast = TRUE)
           )

##confirm number of rows in dataset after filtering (should be 22485)
nrow(COPING_followupA_ong.id)


##FOLLOW UP B
##confirm number of rows in current dataset 
nrow(COPING_followupB.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
COPING_followupB.id <- COPING_followupB.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(waveB,
                      fromLast = TRUE)
           )

##confirm number of rows in dataset after filtering 
nrow(COPING_followupB.id)

##BASELINE
##confirm number of rows in current dataset 
nrow(COPING_baseline.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
COPING_baseline.id <- COPING_baseline.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(ID,
                          fromLast = TRUE)
           ) %>%
  ungroup(ID)

##confirm number of rows in dataset after filtering 
nrow(COPING_baseline.id)

```

## Change COPING follow up A and B from long to wide format (we want this for the numeric ones so we can sum them)
```{r COPING follow up A and B long to wide format}

COPING_followupA.id.long <- COPING_followupA.id %>%
  group_by(waveA) %>%
  tidyr::pivot_wider(id_cols = ID, 
    names_from = waveA, 
                     values_from = c(gad7.pandemic_nervous_anxious_on_edge,
                                     gad7.pandemic_cant_control_worry,
                                     gad7.pandemic_worry_too_much,
                                     gad7.pandemic_trouble_relaxing,
                                     gad7.pandemic_restless,
                                     gad7.pandemic_easily_annoyed,
                                     gad7.pandemic_afraid_something_terrible_will_happen)) 

COPING_followupA_ong.id.long <- COPING_followupA_ong.id %>%
  group_by(waveA) %>%
  tidyr::pivot_wider(id_cols = ID, 
    names_from = waveA, 
                       values_from = c(gad7.pandemic_nervous_anxious_on_edge,
                                     gad7.pandemic_cant_control_worry,
                                     gad7.pandemic_worry_too_much,
                                     gad7.pandemic_trouble_relaxing,
                                     gad7.pandemic_restless,
                                     gad7.pandemic_easily_annoyed,
                                     gad7.pandemic_afraid_something_terrible_will_happen)) 

COPING_followupB.id.long <- COPING_followupB.id %>%
  group_by(waveB) %>%
  tidyr::pivot_wider(id_cols = ID, 
    names_from = waveB, 
                     values_from = c(gad7.pandemic_nervous_anxious_on_edge,
                                     gad7.pandemic_cant_control_worry,
                                     gad7.pandemic_worry_too_much,
                                     gad7.pandemic_trouble_relaxing,
                                     gad7.pandemic_restless,
                                     gad7.pandemic_easily_annoyed,
                                     gad7.pandemic_afraid_something_terrible_will_happen)) 
  

# Check
colnames(COPING_followupA.id.long)
colnames(COPING_followupA_ong.id.long)
colnames(COPING_followupB.id.long)


```
  
# Clean COPING data {.tabset}

## Set minimum and maximum values 
```{r Set minimum and maximum values}
gad.min.scale <- 0
gad.max.scale <- 3
```


## COPING baseline
add wave 0 to the end of all variable names to indicate baseline
```{r Add "_.Wave_0" to the end of all variables COPING baseline}
COPING_baseline.id <- COPING_baseline.id %>% 
  rename_with( ~ paste(.x, ".Wave_0", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(COPING_baseline.id)
```

```{r Add "_unc" to the end of all variables COPING baseline}
COPING_baseline.id <- COPING_baseline.id %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(COPING_baseline.id)
```

```{r COPING baseline inspect the variables}
COPING_baseline.id %>% 
  freq(gad7.pandemic_nervous_anxious_on_edge_.Wave_0_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning}
gad.items.baseline_unc <- COPING_baseline.id %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.baseline_unc
```

### Recode implausuble values
```{r Recode implausible values COPING baseline}
# Recode and clean
COPING_baseline.id <- COPING_baseline.id %>%
   mutate(
     across(all_of(gad.items.baseline_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(COPING_baseline.id)
```
### Make new list of cleaned variables
```{r}
gad.items.baseline_clean <- COPING_baseline.id %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.baseline_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_baseline_imp_n <- COPING_baseline.id %>% 
  select(all_of(gad.items.baseline_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_baseline_imp_n == 0) {
  print(paste0("The number of implausible values in the coping follow up A gad variables is ", gad_baseline_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the coping follow up A gad variables is ", gad_baseline_imp_n, ". Please investigate."))
}
```

### Select only the clean variables and replocate ID to front

Note: keep ID in this data set
```{r}
COPING_baseline.id.clean <- COPING_baseline.id %>% 
  select(!contains("_unc")) 

colnames(COPING_baseline.id.clean)
```

## COPING follow up A

```{r Add "_unc" to the end of all variables COPING follow up A}
COPING_followupA.id.long <- COPING_followupA.id.long %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(COPING_followupA.id.long)
```

```{r COPING follow up A inspect the variables}
COPING_followupA.id.long %>% 
  freq(gad7.pandemic_cant_control_worry_.Wave_03_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning COPING A}
gad.items.followupA_unc <- COPING_followupA.id.long %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.followupA_unc
```

### Recode implausuble values
```{r Recode implausible values COPING A}
# Recode and clean
COPING_followupA.id.long <- COPING_followupA.id.long %>%
   mutate(
     across(all_of(gad.items.followupA_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(COPING_followupA.id.long)
```
### Make new list of cleaned variables
```{r}
gad.items.followupA_clean <- COPING_followupA.id.long %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.followupA_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_followupA_imp_n <- COPING_followupA.id.long %>% 
  select(all_of(gad.items.followupA_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_followupA_imp_n == 0) {
  print(paste0("The number of implausible values in the coping follow up A gad variables is ", gad_followupA_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the coping follow up A gad variables is ", gad_followupA_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
Note: keep ID in this data set
```{r}
COPING_followupA.id.long.clean <- COPING_followupA.id.long %>% 
  select(!contains("_unc")) 

colnames(COPING_followupA.id.long.clean)
```


## COPING follow up A ongoing

```{r Add "_unc" to the end of all variables COPING follow up A ongoing}
COPING_followupA_ong.id.long <- COPING_followupA_ong.id.long %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(COPING_followupA_ong.id.long)
```

```{r COPING follow up A ongoing inspect the variables}
COPING_followupA_ong.id.long %>% 
  freq(gad7.pandemic_nervous_anxious_on_edge_.Wave_05_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning COPING A ongoing}
gad.items.followupA_ong_unc <- COPING_followupA_ong.id.long %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.followupA_ong_unc
```

### Recode implausible values
```{r Recode implausible values COPING A ongoing}
# Recode and clean
COPING_followupA_ong.id.long <- COPING_followupA_ong.id.long %>%
   mutate(
     across(all_of(gad.items.followupA_ong_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(COPING_followupA_ong.id.long)
```

### Make new list of cleaned variables
```{r}
gad.items.followupA_ong_clean <- COPING_followupA_ong.id.long %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.followupA_ong_clean
```

### Check number of implausible values
```{r}
# Check for implausible values
gad_followupA_ong_imp_n <- COPING_followupA_ong.id.long %>% 
  select(all_of(gad.items.followupA_ong_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_followupA_ong_imp_n == 0) {
  print(paste0("The number of implausible values in the coping follow up A ongoing gad variables is ", gad_followupA_ong_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the coping follow up A ongoing gad variables is ", gad_followupA_ong_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
Note: keep ID in this data set
```{r}
COPING_followupA_ong.id.long.clean <- COPING_followupA_ong.id.long %>% 
  select(!contains("_unc")) 

colnames(COPING_followupA_ong.id.long.clean)
```


## COPING follow up B

```{r Add "_unc" to the end of all variables COPING follow up B}
COPING_followupB.id.long <- COPING_followupB.id.long %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning COPING B}
gad.items.followupB_unc <- COPING_followupB.id.long %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.followupB_unc
```

### Recode implausible values
```{r Recode implausible valuesCOPING B}
# Recode and clean
COPING_followupB.id.long <- COPING_followupB.id.long %>%
   mutate(
     across(all_of(gad.items.followupB_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(COPING_followupB.id.long)
```
### Make new list of cleaned variables
```{r}
gad.items.followupB_clean <- COPING_followupB.id.long %>% 
  select(!contains("_unc")) %>% 
  select(!"ID") %>% 
  colnames()

gad.items.followupB_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_followupB_imp_n <- COPING_followupB.id.long %>% 
  select(all_of(gad.items.followupB_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_followupB_imp_n == 0) {
  print(paste0("The number of implausible values in the coping follow up B gad variables is ", gad_followupB_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the coping follow up B gad variables is ", gad_followupB_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
```{r}
COPING_followupB.id.long.clean <- COPING_followupB.id.long %>% 
  select(!contains("_unc"))

colnames(COPING_followupB.id.long.clean)
```


# Merge COPING Baseline, follow up A and B surveys
Note: full join (i.e. to get all participants in all three data sets)
```{r Merge COPING follow up A and B surveys}
gad.merging <- list(COPING_baseline.id.clean,
                    COPING_followupA_ong.id.long.clean,
                       COPING_followupA.id.long.clean,
                       COPING_followupB.id.long.clean)


gad.COPING <- plyr::join_all(gad.merging,
#                    by = "ID", #if included, this stops columns with the same name from combined. Allowing to merge on all common names columns
                    type = "full")

# relocate ID to the beginning

gad.COPING <- gad.COPING %>%
  relocate(ID, .before = startDate)
  
  
  
# check
dim(COPING_followupA.id.long.clean)
dim(COPING_followupA_ong.id.long.clean)
dim(COPING_followupB.id.long.clean)
dim(COPING_baseline.id.clean)
dim(gad.COPING)

colnames(gad.COPING)


# reorder so that it is easy to see each wave in place.
gad.COPING.reordered <- gad.COPING %>% 
  select(order(names(gad.COPING)),
         -startDate,
         -endDate) %>%
  relocate(ID, .before = gad7.pandemic_afraid_something_terrible_will_happen_.Wave_0)

colnames(gad.COPING.reordered)

```
  
# RAMP data preprocessing {.tabset}
## RAMP baseline 
```{r}
# read in baseline data
RAMP_baseline = readRDS(paste0(ilovedata,"/data_raw/2021-02-18/ramp/gad7_ramp.rds"))

# Check column names
RAMP_baseline %>%
  colnames()

# Check dimensions
RAMP_baseline %>%
  dim()

# Look at top rows of the data frame
RAMP_baseline %>% 
  head()
```

```{r}
#Recode column names to harmonised variable names

#gad.x.0 - pre pandemic
#gad.x.1 - Baseline current
#GAD.pandemic.change - item asking if this is different from before pandemic

RAMP_baseline.id <- RAMP_baseline %>% #new dataset with ID
  drop_na("Login ID") %>% # Drop NAs
  select(
         ID = "Login ID", # ID
         gad7.pandemic_nervous_anxious_on_edge = gad7.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad7.control_worrying_stop,
         gad7.pandemic_worry_too_much = gad7.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad7.trouble_relaxing,
         gad7.pandemic_restless = gad7.sit_hard_restless,
         gad7.pandemic_easily_annoyed = gad7.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad7.awful_feeling_afraid_happen)
         

# Inspect colnames
colnames(RAMP_baseline.id)


```


```{r}
#seen but not answered (-99 & -77 ) as NA
RAMP_baseline.id <- RAMP_baseline.id %>%
  mutate_at(vars(starts_with("gad")),
            funs(case_when(

             . == -77 ~ NA_real_,
             TRUE ~  .)))
  

```

## RAMP follow up A

```{r Read in RAMP follow up A data}
# Read in the data
RAMP_followupA <- readRDS(file = paste0(ilovedata, "/data_raw/2021-04-09/ramp_followupa/gad_ramp_followupa.rds"))

# Check column names
RAMP_followupA %>%
  colnames()

# Check dimensions
RAMP_followupA %>%
  dim()

# Look at top rows of the data frame
RAMP_followupA %>% 
  head()
```


```{r }

RAMP_followupA.id <- RAMP_followupA %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop NAs
  add_column(sample = "RAMP_followupA", .after = "externalDataReference") %>% #create new column 
  select(
         ID = externalDataReference, # ID
         sample,
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad.control_worrying_stop,
         gad7.pandemic_worry_too_much = gad.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad.trouble_relaxing,
         gad7.pandemic_restless = gad.sit_hard_restless,
         gad7.pandemic_easily_annoyed = gad.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad.awful_happen_feeling_afraid)

# Inspect colnames
colnames(RAMP_followupA.id)

```
  

## RAMP follow up B

```{r Read in RAMP follow up B data}
# Read in the data
RAMP_followupB <- readRDS(file = paste0(ilovedata, "/data_raw/2021-04-09/ramp_followupb/gad_ramp_followupb.rds"))

# Check column names
RAMP_followupB %>%
  colnames()

# Check dimensions
RAMP_followupB %>%
  dim()

# Look at top rows of the data frame
RAMP_followupB %>% 
  head()
```

Select & rename relevant columns (will be a function at some point)
```{r}


RAMP_followupB.id <- RAMP_followupB %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop NAs
  add_column(sample = "RAMP_followupB", .after = "externalDataReference") %>% #create new column 
  select(
         ID = externalDataReference, # ID
         sample,
         startDate,
         endDate,
         gad7.pandemic_nervous_anxious_on_edge = gad.feeling_nervous_anxious_or_on_edge,
         gad7.pandemic_cant_control_worry = gad.stop_control_worrying,
         gad7.pandemic_worry_too_much = gad.worrying_too_much_about_different_things,
         gad7.pandemic_trouble_relaxing = gad.trouble_relaxing,
         gad7.pandemic_restless = gad.hard_sit_restless,
         gad7.pandemic_easily_annoyed = gad.becoming_easily_annoyed_or_irritable,
         gad7.pandemic_afraid_something_terrible_will_happen = gad.awful_feeling_afraid_happen) 


# Inspect colnames
colnames(RAMP_followupB.id)

```

## Creating follow up time points RAMP 

### Create waves within the FOLLOW UP DATA 
Note: dates from google sheet from Kirstin
Checked with Gerome - set start date as the date the survey was released, and keep window open until the DAY BEFORE the next survey was released

these are in order, incorporating everyone into wave according to date of completion as per the COPING above. 

```{r}

# April/May (wave 1) - FOLLOW UP A
ramp_start1 <- as.POSIXct("2020-04-21")
ramp_end1 <-  as.POSIXct("2020-05-04")  

# May (wave 2) - FOLLOW UP B
ramp_start2 <- as.POSIXct("2020-05-05")
ramp_end2<-  as.POSIXct("2020-05-18")  

# May/June (wave 3) - FOLLOW UP A
ramp_start3 <- as.POSIXct("2020-05-19")
ramp_end3 <-  as.POSIXct("2020-06-01") 

# June 1 (wave 4) - FOLLOW UP B
ramp_start4 <- as.POSIXct("2020-06-02")
ramp_end4<-  as.POSIXct("2020-06-15") 

# June 2 (wave 5) - FOLLOW UP A
ramp_start5 <- as.POSIXct("2020-06-16")
ramp_end5 <-  as.POSIXct("2020-06-29") 

# June/July (wave 6) - FOLLOW UP B
ramp_start6 <- as.POSIXct("2020-06-30") 
ramp_end6 <-  as.POSIXct("2020-07-13") 

# July 1 (wave 7) - FOLLOW UP A
ramp_start7 <- as.POSIXct("2020-07-14")
ramp_end7 <-  as.POSIXct("2020-07-27") 

# July/August (wave 8) - FOLLOW UP B
ramp_start8 <- as.POSIXct("2020-07-28")
ramp_end8 <-  as.POSIXct("2020-08-24") 

# August/September (wave 9) - FOLLOW UP A
ramp_start9 <- as.POSIXct("2020-08-25")
ramp_end9 <-  as.POSIXct("2020-09-21") 

# September/October (wave 10) - FOLLOW UP B
ramp_start10 <- as.POSIXct("2020-09-22")
ramp_end10 <-  as.POSIXct("2020-10-19") 

# October/November (wave 11) - FOLLOW UP A
ramp_start11 <- as.POSIXct("2020-10-20")
ramp_end11 <-  as.POSIXct("2020-11-16") 

# November/December (wave 12) - FOLLOW UP B
ramp_start12 <- as.POSIXct("2020-11-17")
ramp_end12 <-  as.POSIXct("2020-12-14") 

# December/January (wave 13) - FOLLOW UP A
ramp_start13 <- as.POSIXct("2020-12-15")
ramp_end13 <-  as.POSIXct("2021-01-18") 

# January/February (wave 14) - FOLLOW UP B
ramp_start14 <- as.POSIXct("2021-01-19")
ramp_end14 <-  as.POSIXct("2021-02-15") 

# February/March (wave 15) - FOLLOW UP A
ramp_start15 <- as.POSIXct("2021-02-16")
ramp_end15 <-  as.POSIXct("2021-03-15")

# March/April (wave 16) - FOLLOW UP B
ramp_start16 <- as.POSIXct("2021-03-16")
ramp_end16 <-  as.POSIXct("2021-04-19")

# April/May (wave 17) - FOLLOW UP A
ramp_start17 <- as.POSIXct("2021-04-20")
ramp_end17 <-  as.POSIXct("2021-05-10")

# May (wave 18) - FOLLOW UP B
ramp_start18 <- as.POSIXct("2021-05-11")
ramp_end18 <-  as.POSIXct("2021-05-31")

# June (wave 19) - FOLLOW UP A
ramp_start19 <- as.POSIXct("2021-06-01")
ramp_end19 <-  as.POSIXct("2021-06-28")


#JM**do we have data beyond this?
## KLP corrected the below to ensure 6 people who were NA (1 in wave A, 5 in wave B) are correctly allocated to the correct wave. easy check for dates for these wave NAs is to run the following after you run these chunks the first time: RAMP_followupA.id$endDate[is.na(RAMP_followupA.id$waveA)]

RAMP_followupA.id <- RAMP_followupA.id %>%
  mutate(waveA = case_when(startDate >= ramp_start1 & startDate < ramp_start2 ~ ".Wave_01",
                           startDate >= ramp_start2 & startDate <= ramp_end2 ~ ".Wave_02",
                            startDate >= ramp_start3 & startDate <= ramp_end3 ~ ".Wave_03",
                           startDate >= ramp_start4 & startDate <= ramp_end4 ~ ".Wave_04",
                            startDate >= ramp_start5 & startDate <= ramp_end5 ~ ".Wave_05",
                           startDate >= ramp_start6 & startDate <= ramp_end6 ~ ".Wave_06",
                            startDate >= ramp_start7 & startDate <= ramp_end7 ~ ".Wave_07",
                           startDate >= ramp_start8 & startDate <= ramp_end8 ~ ".Wave_08",
                            startDate >= ramp_start9 & startDate <= ramp_end9 ~ ".Wave_09",
                           startDate >= ramp_start10 & startDate <= ramp_end10 ~ ".Wave_10",
                            startDate >= ramp_start11 & startDate <= ramp_end11 ~ ".Wave_11",
                           startDate >= ramp_start12 & startDate <= ramp_end12 ~ ".Wave_12",
                            startDate >= ramp_start13 & startDate <= ramp_end13 ~ ".Wave_13",
                              startDate >= ramp_start14 & startDate <= ramp_end14 ~ ".Wave_14",
                            startDate >= ramp_start15 & startDate <= ramp_end15 ~ ".Wave_15",
                            startDate >= ramp_start16 & startDate <= ramp_end16 ~ ".Wave_16",
                           startDate >= ramp_start17 & startDate <= ramp_end17 ~ ".Wave_17",
                           startDate >= ramp_start18 & startDate <= ramp_end18 ~ ".Wave_18",
                            startDate >= ramp_start19 & startDate <= ramp_end19 ~ ".Wave_19")
         )

RAMP_followupB.id <- RAMP_followupB.id %>%
  mutate(waveB = case_when(startDate >= ramp_start1 & startDate < ramp_end1 ~ ".Wave_1A_in_B", # should be impossible to exist
                           startDate >= ramp_start2 & startDate < ramp_start3 ~ ".Wave_02",
                            startDate >= ramp_start3 & startDate <= ramp_end3 ~ ".Wave_03",
                           startDate >= ramp_start4 & startDate <= ramp_end4 ~ ".Wave_04",
                            startDate >= ramp_start5 & startDate <= ramp_end5 ~ ".Wave_05",
                           startDate >= ramp_start6 & startDate <= ramp_end6 ~ ".Wave_06",
                            startDate >= ramp_start7 & startDate <= ramp_end7 ~ ".Wave_07",
                           startDate >= ramp_start8 & startDate <= ramp_end8 ~ ".Wave_08",
                            startDate >= ramp_start9 & startDate <= ramp_end9 ~ ".Wave_09",
                           startDate >= ramp_start10 & startDate <= ramp_end10 ~ ".Wave_10",
                            startDate >= ramp_start11 & startDate <= ramp_end11 ~ ".Wave_11",
                           startDate >= ramp_start12 & startDate <= ramp_end12 ~ ".Wave_12",
                            startDate >= ramp_start13 & startDate <= ramp_end13 ~ ".Wave_13",
                              startDate >= ramp_start14 & startDate <= ramp_end14 ~ ".Wave_14",
                            startDate >= ramp_start15 & startDate <= ramp_end15 ~ ".Wave_15",
                            startDate >= ramp_start16 & startDate <= ramp_end16 ~ ".Wave_16",
                           startDate >= ramp_start17 & startDate <= ramp_end17 ~ ".Wave_17",
                           startDate >= ramp_start18 & startDate <= ramp_end18 ~ ".Wave_18",
                            startDate >= ramp_start19 & startDate <= ramp_end19 ~ ".Wave_19"))



```


### check for number of entries per wave

```{r check for number of entries per wave RAMP}

RAMP_followupA.id %>%
  group_by(waveA) %>%
  count()


RAMP_followupB.id %>%
  group_by(waveB) %>%
  count()
```

### Identifying duplicate IDs in a single wave
```{r Identifying duplicate IDs in a single wave RAMP}

##Identify dup IDs in a single wave (baseline)
RAMP_baseline.id %>%
   group_by(ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)

##Identify dup IDs in a single wave (follow up A)
RAMP_followupA.id %>%
   group_by(waveA, ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)

##Identify dup IDs in a single wave (B) 
RAMP_followupB.id %>%
   group_by(waveB, ID) %>%
   summarize(N = n()) %>%
   filter(N > 1)


```

**removing duplicates, retaining the latest possible data where there are repeats**

### Want the LATER data entry from people who answered twice within a single wave 
We want there to be unique IDs within each of the waves
```{r}

##baseline

##confirm number of rows in current dataset
nrow(RAMP_baseline.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
RAMP_baseline.id <- RAMP_baseline.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(ID,
                       fromLast = TRUE)
          
           )  %>%
             ungroup()

##confirm number of rows in dataset after filtering 
nrow(RAMP_baseline.id)


##FOLLOW UP A
##confirm number of rows in current dataset
nrow(RAMP_followupA.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
RAMP_followupA.id <- RAMP_followupA.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(waveA,
                      fromLast = TRUE)
           )

##confirm number of rows in dataset after filtering 
nrow(RAMP_followupA.id)

##FOLLOW UP B
##confirm number of rows in current dataset 
nrow(RAMP_followupB.id)

#Filter out duplicated IDs AND wave, keeping the LAST entry
RAMP_followupB.id <- RAMP_followupB.id %>% 
    group_by(ID) %>% 
    filter(!duplicated(waveB,
                      fromLast = TRUE)
           )

##confirm number of rows in dataset after filtering 
nrow(RAMP_followupB.id)
```

## Change RAMP follow up A and B from long to wide format (we want this for the numeric ones so we can sum them)
```{r RAMP follow up A and B long to wide format}

RAMP_followupA.id.long <- RAMP_followupA.id %>%
  group_by(waveA) %>%
  tidyr::pivot_wider(id_cols = ID, 
    names_from = waveA, 
                     values_from = c(gad7.pandemic_nervous_anxious_on_edge,
                                     gad7.pandemic_cant_control_worry,
                                     gad7.pandemic_worry_too_much,
                                     gad7.pandemic_trouble_relaxing,
                                     gad7.pandemic_restless,
                                     gad7.pandemic_easily_annoyed,
                                     gad7.pandemic_afraid_something_terrible_will_happen)) 


RAMP_followupB.id.long <- RAMP_followupB.id %>%
  group_by(waveB) %>%
  tidyr::pivot_wider(id_cols = ID, 
    names_from = waveB, 
                     values_from = c(gad7.pandemic_nervous_anxious_on_edge,
                                     gad7.pandemic_cant_control_worry,
                                     gad7.pandemic_worry_too_much,
                                     gad7.pandemic_trouble_relaxing,
                                     gad7.pandemic_restless,
                                     gad7.pandemic_easily_annoyed,
                                     gad7.pandemic_afraid_something_terrible_will_happen)) 
  

# Check
colnames(RAMP_followupA.id.long)
colnames(RAMP_followupB.id.long)


```



# clean RAMP data {.tabset}

## RAMP Baseline
add wave 0 to the end of all variable names to indicate baseline
```{r Add "_.Wave_0" to the end of all variables RAMP baseline}
RAMP_baseline.id <- RAMP_baseline.id %>% 
  rename_with( ~ paste(.x, ".Wave_0", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(RAMP_baseline.id)
```

```{r Add "_unc" to the end of all variables RAMP baseline}
RAMP_baseline.id <- RAMP_baseline.id %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(RAMP_baseline.id)
```

```{r RAMP Baseline inspect the variables}
RAMP_baseline.id %>% 
  freq(gad7.pandemic_cant_control_worry_.Wave_0_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning RAMP baseline}
gad.items.baseline_unc <- RAMP_baseline.id %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.baseline_unc
```

### Recode implausuble values
```{r Recode implausible values RAMP baseline}
# Recode and clean
RAMP_baseline.id <- RAMP_baseline.id %>%
   mutate(
     across(all_of(gad.items.baseline_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(RAMP_baseline.id)
```
### Make new list of cleaned variables
```{r}
gad.items.baseline_clean <- RAMP_baseline.id %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.baseline_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_baseline_imp_n <- RAMP_baseline.id %>% 
  select(all_of(gad.items.baseline_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_baseline_imp_n == 0) {
  print(paste0("The number of implausible values in the RAMP Baseline GAD variables is ", gad_baseline_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the RAMP Baseline GAD variables is ", gad_baseline_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
Note: keep ID in this data set
```{r}
RAMP_baseline.id.clean <- RAMP_baseline.id %>% 
  select(!contains("_unc")) 

colnames(RAMP_baseline.id.clean)
```


## RAMP follow up A

```{r Add "_unc" to the end of all variablesRAMP follow up A}
RAMP_followupA.id.long <- RAMP_followupA.id.long %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(RAMP_followupA.id.long)
```

```{r RAMP follow up A inspect the variables}
RAMP_followupA.id.long %>% 
  freq(gad7.pandemic_nervous_anxious_on_edge_.Wave_01_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaningRAMP A}
gad.items.followupA_unc <- RAMP_followupA.id.long %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.followupA_unc
```

### Recode implausuble values
```{r Recode implausible values RAMP A}
# Recode and clean
RAMP_followupA.id.long <- RAMP_followupA.id.long %>%
   mutate(
     across(all_of(gad.items.followupA_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(RAMP_followupA.id.long)
```


### Make new list of cleaned variables
```{r}
gad.items.followupA_clean <- RAMP_followupA.id.long %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.followupA_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_followupA_imp_n <- RAMP_followupA.id.long %>% 
  select(all_of(gad.items.followupA_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_followupA_imp_n == 0) {
  print(paste0("The number of implausible values in the RAMP follow up A GAD variables is ", gad_followupA_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the RAMP follow up A GAD variables is ", gad_followupA_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
Note: keep ID in this data set
```{r}
RAMP_followupA.id.long.clean <- RAMP_followupA.id.long %>% 
  select(!contains("_unc")) 

colnames(RAMP_followupA.id.long.clean)
```

## RAMP follow up B

```{r Add "_unc" to the end of all variables RAMP follow up B}
RAMP_followupB.id.long <- RAMP_followupB.id.long %>% 
  rename_with( ~ paste(.x, "unc", sep = "_"), starts_with("gad")) # Add suffix "unc" for all uncleaned data columns

# check
colnames(RAMP_followupB.id.long)
```

```{r RAMP follow up B inspect the variables}
RAMP_followupB.id.long %>% 
  freq(gad7.pandemic_nervous_anxious_on_edge_.Wave_02_unc)
```

### Make list of variables for cleaning
```{r Make list of variables for cleaning RAMP B}
gad.items.followupB_unc <- RAMP_followupB.id.long %>% 
  select(contains("_unc")) %>% 
  colnames()

gad.items.followupB_unc
```

### Recode implausuble values
```{r Recode implausible values RAMP B}
# Recode and clean
RAMP_followupB.id.long <- RAMP_followupB.id.long %>%
   mutate(
     across(all_of(gad.items.followupB_unc),
            .fns = list(clean = ~case_when( # add "_clean" onto the variables you are cleaning
              . == -77 | . == -88 | . == -99 ~ ., # leave as is 
              . < gad.min.scale | . > gad.max.scale ~ -66, # recode as implausible value
              TRUE ~ . # leave as is
            )
            )
     )
   ) %>%
   rename_at(
     vars(contains( "_unc_clean")), # specify variables that now contain "_clean"
     list(~paste0(gsub("_unc_clean", "", .))) # remove the "_clean" now that they have been cleaned
   )

# Check
colnames(RAMP_followupB.id.long)
```
### Make new list of cleaned variables
```{r}
gad.items.followupB_clean <- RAMP_followupB.id.long %>% 
  select(!contains("_unc")) %>% # select the cleaned variables (i.e. they don't contain the phrase "_unc")
  select(!"ID") %>% # deselect the ID variable
  colnames()

gad.items.followupB_clean
```
### Check number of implausible values
```{r}
# Check for implausible values
gad_followupB_imp_n <- RAMP_followupB.id.long %>% 
  select(all_of(gad.items.followupB_clean)) %>% 
  filter(. == -66) %>% 
  nrow()

# If statement
if (gad_followupB_imp_n == 0) {
  print(paste0("The number of implausible values in the RAMP follow up B GAD variables is ", gad_followupB_imp_n, ". Can leave these variables as they are."))
} else {
  print(paste0("The number of implausible values in the RAMP follow up B GAD variables is ", gad_followupB_imp_n, ". Please investigate."))
}
```

### Select only the clean variables
Note: keep ID in this data set
```{r}
RAMP_followupB.id.long.clean <- RAMP_followupB.id.long %>% 
  select(!contains("_unc")) 

colnames(RAMP_followupB.id.long.clean)
```

# Save baseline RAMP cleaned data items only for CFA
```{r}

saveRDS(object = RAMP_baseline.id.clean, file = paste0("../../../data_clean/gad/gad.clean_baseline_items.RAMP",  ".rds"))

```

# Merge RAMP baseline, follow up A and B surveys
Note: full join (i.e. to get all participants in all three data sets)
```{r Merge RAMP follow up A and B surveys}
gad.merging <- list(RAMP_baseline.id.clean,
                       RAMP_followupA.id.long.clean,
                       RAMP_followupB.id.long.clean)


gad.RAMP <- plyr::join_all(gad.merging,
     #               by = "ID", freeing to merge on all common columns so we dont drop anyything needlessly
                    type = "full")

  
# check
dim(RAMP_followupA.id.long.clean)
dim(RAMP_followupB.id.long.clean)
dim(RAMP_baseline.id.clean)
dim(gad.RAMP)

colnames(gad.RAMP)


# reorder so that it is easy to see each wave in place.
gad.RAMP.reordered <- gad.RAMP %>% 
  select(order(names(gad.RAMP))) %>%
  relocate(ID, .before = gad7.pandemic_afraid_something_terrible_will_happen_.Wave_0)

colnames(gad.RAMP.reordered)

```

# merge COPING and RAMP all wave data

Merge by all common columns so that we dont duplicate waves. This is effectively an rbind action (adding a row for every case but keeping columns standard across)

```{r merge RAMP and COPING}

# add a sample columns
gad.RAMP.for.merging <- gad.RAMP.reordered %>%
  mutate(sample = "RAMP") %>%
  relocate(sample, .after = ID)

gad.COPING.for.merging <- gad.COPING.reordered %>%
  mutate(sample = "COPING") %>%
  relocate(sample, .after = ID)

gad.merged <- full_join(gad.RAMP.for.merging,gad.COPING.for.merging)

dim(gad.RAMP.for.merging)
dim(gad.COPING.for.merging)
dim(gad.merged)
names(gad.merged)
```

## drop data from waves after 6 April 2021 (see pre registration for re-agreed data boundaries)

```{r drop later waves}
gad.clean <- gad.merged %>%
  select(!contains("Wave_18"))

names(gad.clean)
```

# create sum scores
scoring variables to use in function below
```{r}
#Scoring variables
GAD.n.items = 7 # Enter here the total number of items of the questionnaire
GAD.maximum.missing.items = 2 # Enter here the number of required items a participant can miss before they are dropped

#Limits for data cleaning
GAD.total.score_upper_limit = 21
GAD.total.score_lower_limit = 0

GAD.min.value = 0
GAD.max.value = 3
```

### make -77 NA
This will mean we can no longer distinguish between missing variable andsomeone who is missing altogether(did not complete survey) but this should be evident from the number of peope whos NA == 7 per wave.

```{r recalculate - 77}
gad.clean<- na_if(gad.clean, -77)
```


## add columns for sum scores for each wave. {.tabset}
use functions that generate items for gad using wave number as a user input. This function is specific to my data naming conventions.

Use a second function to calculate the total scores. This can be applied to any scale. it takes a dataframe, list of keys, list of items, minimum and maximum item values, and maximum allowed missing items. It calculates total scores, using mean imputation for any missing items. It drops scores for anyone who misses more than the maximum allowed items. It describes how many missing items there are, and the total scores after dropping anyone for high missingness, and shows the internal consistency metrics for the scale. Finally, it returns  column of total scores as output.


***Will do a chunk for every wave to make output clear and easy to distinguish and examine for every wave***

### Baseline 
```{r baseline sumscore test}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items(0)

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_0 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 01
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("01")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_01 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 02
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("02")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_02 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 03
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("03")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_03 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 04
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("04")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_04 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 05
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("05")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_05 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 06
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("06")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_06 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 07
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("07")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_07 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 08
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("08")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_08 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 09
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("09")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_09 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 10
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("10")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_10 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 11
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("11")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_11 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 12
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("12")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_12 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 13
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("13")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_13 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 14
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("14")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_14 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 15
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("15")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_15 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 16
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("16")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_16 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

### Follow up 17
```{r}

keys_gad <- c(1,1,1,1,1,1,1)
items_gad <- generate_items("17")

gad.clean <- gad.clean %>%
  mutate(gad.total_Wave_17 = calculate_totals(dataframe=.,
                                                itemlist = items_gad,
                                                keylist = keys_gad,
                                                minval = GAD.min.value,
                                                maxval = GAD.max.value,
                                                maxmissing = GAD.maximum.missing.items))
```

# select total scores per wave and save this dataset

```{r drop item data}

gad.totals.clean <-
  gad.clean %>%
  select(ID, sample,
         starts_with("gad.total_Wave_"))
```

## save
```{r save final data}
saveRDS(object = gad.totals.clean, file = paste0("../../../data_clean/gad/gad.clean_merged_total_scores",  ".rds"))
```


## save as csv without any rown names for MPLUS and NA  as -99 

create a list of column names in order to save alongside the data file
```{r mplus remove id make name codebook}

gad.mplus <- gad.totals.clean %>%
  select(-sample) 

gad.mplus.names <- names(gad.mplus)
gad.mplus.names.columns <- seq(1,length(gad.mplus.names))

gad.mplus.names <- data.frame(cbind(gad.mplus.names,gad.mplus.names.columns))

names(gad.mplus.names) <- c("Variable","Column")


gad.mplus[is.na(gad.mplus)] <- -99
```


## make a new hased ID column with only numbers and save the linking file for later steps
MPlus will only allow numeric variables. 

hashed ID is already totally anonymised and disconnected from original dataset, so will save it with the other data as there is no additional risk of data linkage by doing so.

```{r numeric hashed id}
# create a random integer ID for each row, without duplication
gad.mplus$hash_id <- sample(1:100000,dim(gad.mplus)[1],replace=FALSE)

```


### create a linked id file

```{r linked ids}

gad.id.lnk <- gad.mplus %>%
  select(ID, hash_id)

```

### remove original ID and move hash id to the front
```{r remove ID relocate hash id}

gad.mplus <- gad.mplus %>%
  relocate(hash_id, .before = ID) %>%
  select(!ID)
```

## Drop timepoints with zero covariance covarage (no overlap between time points)

due to RAMP or COPING not having data 

Also create a keyed name dictionary

```{r mplus revised data}

gad.mplus.reduced <-gad.mplus %>%
  select(-gad.total_Wave_01,
         -gad.total_Wave_02,
         -gad.total_Wave_17)

gad.mplus.reduced.names <- names(gad.mplus.reduced)
gad.mplus.reduced.names.columns <- seq(1,length(gad.mplus.reduced.names))
gad.mplus.reduced.names <- data.frame(cbind(gad.mplus.reduced.names,gad.mplus.reduced.names.columns))

```

## remove column names
```{r remove col names}

names(gad.mplus) <- NULL
names(gad.mplus.reduced) <- NULL

```

##save .dat file for MPlus without headers, and corresponding orderd list of variables

```{r save plus dat files}

write.table(gad.mplus, "../../../data_clean/gad/gad.clean_merged_total_scores.csv",row.names = FALSE)
write.table(gad.mplus.reduced, "../../../data_clean/gad/gad.clean_merged_total_scores_reduced.csv",row.names = FALSE)
write_csv(gad.id.lnk, "../../../data_clean/gad/gad.mplus_hash_id_link_file.csv")
write_csv(gad.mplus.names, "../../../data_clean/gad/gad.clean_merged_total_scores_codebook.csv")
write_csv(gad.mplus.reduced.names, "../../../data_clean/gad/gad.clean_merged_total_scores_reduced_codebook.csv")

```

# summary table 

## create a  summary table for every wave

each component table by wave
```{r built summary table 0}

summary_table_0 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_0,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_0,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_0)))  %>%
    mutate(sample = "Combined",
      time.point = "Baseline") %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_0 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_0,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_0,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_0)))  %>%
    mutate(time.point = "Baseline" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_0 <- rbind (summary_table_sample_0,summary_table_0)

```



```{r built summary table 01}

summary_table_01 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_01,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_01,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_01)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 01" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_01 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_01,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_01,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_01)))  %>%
    mutate(time.point = "Follow up 01" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_01 <- rbind (summary_table_sample_01,summary_table_01)

```


```{r built summary table 02}

summary_table_02 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_02,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_02,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_02)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 02" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_02 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_02,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_02,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_02)))  %>%
    mutate(time.point = "Follow up 02" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_02 <- rbind (summary_table_sample_02,summary_table_02)

```

```{r built summary table 03}

summary_table_03 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_03,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_03,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_03)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 03" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_03 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_03,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_03,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_03)))  %>%
    mutate(time.point = "Follow up 03" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_03 <- rbind (summary_table_sample_03,summary_table_03)

```

```{r built summary table 04}

summary_table_04 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_04,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_04,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_04)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 04" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_04 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_04,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_04,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_04)))  %>%
    mutate(time.point = "Follow up 04" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_04 <- rbind (summary_table_sample_04,summary_table_04)

```

```{r built summary table 05}

summary_table_05 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_05,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_05,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_05)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 05" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_05 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_05,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_05,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_05)))  %>%
    mutate(time.point = "Follow up 05" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_05 <- rbind (summary_table_sample_05,summary_table_05)

```

```{r built summary table 06}

summary_table_06 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_06,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_06,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_06)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 06" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_06 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_06,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_06,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_06)))  %>%
    mutate(time.point = "Follow up 06" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_06 <- rbind (summary_table_sample_06,summary_table_06)

```

```{r built summary table 07}

summary_table_07 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_07,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_07,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_07)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 07" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_07 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_07,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_07,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_07)))  %>%
    mutate(time.point = "Follow up 07" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_07 <- rbind (summary_table_sample_07,summary_table_07)

```

```{r built summary table 08}

summary_table_08 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_08,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_08,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_08)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 08" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_08 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_08,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_08,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_08)))  %>%
    mutate(time.point = "Follow up 08" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_08 <- rbind (summary_table_sample_08,summary_table_08)

```

```{r built summary table 09}

summary_table_09 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_09,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_09,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_09)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 09" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_09 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_09,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_09,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_09)))  %>%
    mutate(time.point = "Follow up 09" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_09 <- rbind (summary_table_sample_09,summary_table_09)

```

```{r built summary table 10}

summary_table_10 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_10,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_10,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_10)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 10" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_10 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_10,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_10,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_10)))  %>%
    mutate(time.point = "Follow up 10" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_10 <- rbind (summary_table_sample_10,summary_table_10)

```

```{r built summary table 11}

summary_table_11 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_11,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_11,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_11)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 11" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_11 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_11,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_11,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_11)))  %>%
    mutate(time.point = "Follow up 11" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_11 <- rbind (summary_table_sample_11,summary_table_11)

```

```{r built summary table 12}

summary_table_12 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_12,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_12,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_12)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 12" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_12 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_12,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_12,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_12)))  %>%
    mutate(time.point = "Follow up 12" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_12 <- rbind (summary_table_sample_12,summary_table_12)

```

```{r built summary table 13}

summary_table_13 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_13,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_13,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_13)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 13" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_13 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_13,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_13,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_13)))  %>%
    mutate(time.point = "Follow up 13" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_13 <- rbind (summary_table_sample_13,summary_table_13)

```

```{r built summary table 14}

summary_table_14 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_14,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_14,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_14)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 14" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_14 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_14,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_14,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_14)))  %>%
    mutate(time.point = "Follow up 14" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_14 <- rbind (summary_table_sample_14,summary_table_14)

```

```{r built summary table 15}

summary_table_15 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_15,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_15,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_15)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 15" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_15 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_15,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_15,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_15)))  %>%
    mutate(time.point = "Follow up 15" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_15 <- rbind (summary_table_sample_15,summary_table_15)

```

```{r built summary table 16}

summary_table_16 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_16,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_16,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_16)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 16" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_16 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_16,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_16,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_16)))  %>%
    mutate(time.point = "Follow up 16" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_16 <- rbind (summary_table_sample_16,summary_table_16)

```

```{r built summary table 17}

summary_table_17 <- 
  
  gad.totals.clean %>%
  summarise(mean = mean(gad.total_Wave_17,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_17,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_17)))  %>%
    mutate(sample = "Combined",
      time.point = "Follow up 17" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)

summary_table_sample_17 <- 
  
  gad.totals.clean %>%
  group_by(sample) %>%
  summarise(mean = mean(gad.total_Wave_17,na.rm = TRUE),
            standard.deviation = sd(gad.total_Wave_17,na.rm = TRUE),
            valid.data.points =  sum(!is.na(gad.total_Wave_17)))  %>%
    mutate(time.point = "Follow up 17" ) %>%
  relocate(time.point,sample,valid.data.points, "mean", standard.deviation)
  

table_time_17 <- rbind (summary_table_sample_17,summary_table_17)

```

## join all tables


```{r join all waves}

full_table <- rbind(table_time_0,table_time_01,table_time_02,table_time_03,table_time_04,table_time_05,
                    table_time_06,table_time_07,table_time_08,table_time_09,table_time_10,
                    table_time_11,table_time_12,table_time_13,table_time_14,table_time_15,
                    table_time_16,table_time_17)

print(full_table)
```

## prettify and save with KABLE (colour combined rows)

```{r create an index list to specify coloured rows}
colour.me <- which(full_table$sample == "Combined")
```

```{r make kable table}

pretty_table <- full_table %>%
  kable(booktabs = T,
        align='llccc',
        digits = 2,
        col.names = str_to_title(gsub("[.]", " ", names(full_table)))) %>%
  kable_styling() %>%
  row_spec(colour.me,bold=T,background = "lightgrey") %>%
  row_spec(0,bold=T,background = "grey",font_size = 16)

pretty_table 
```
```{r save kable}

save_file <- file.path(dirname(dirname(getwd())),"output/gad.all_waves_summary_table.html")

save_kable(pretty_table,
           save_file)

```


# examine data (total scores) for normality

## descriptives


```{r}

### Check distributions of raw data, square root transformed data and log transformed data (bring above 1 first...) using histograms

gad.totals.clean %>%
  describe(.)

```

##  histograms

```{r differentials_variable_transformation_histograms,fig.height=12,fig.width=8}

layout(matrix(c(1:18), nrow=6, byrow=T))

hist(gad.totals.clean$gad.total_Wave_0, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_01, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_02, breaks="FD")

hist(gad.totals.clean$gad.total_Wave_03, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_04, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_05, breaks="FD")

hist(gad.totals.clean$gad.total_Wave_06, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_07, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_08, breaks="FD")

hist(gad.totals.clean$gad.total_Wave_09, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_10, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_11, breaks="FD")

hist(gad.totals.clean$gad.total_Wave_12, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_13, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_14, breaks="FD")

hist(gad.totals.clean$gad.total_Wave_15, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_16, breaks="FD")
hist(gad.totals.clean$gad.total_Wave_17, breaks="FD")

layout(1)


```

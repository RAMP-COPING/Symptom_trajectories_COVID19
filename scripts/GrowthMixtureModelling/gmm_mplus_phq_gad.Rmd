---
title: "Run Latent Class Growth Analyses and Growth Mixture Modelling for RAMP longitudinal abnalyses of common mental health symptoms: GAD and PHQ"
author: "K L Purves"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: false
    number_sections: false
    highlight: monochrome
    theme: cerulean
code_folding: show

html_notebook:
  theme: cerulean
toc: yes
---

This workbook centralises analyses of the PHQ-9 and GAD-7 total scores longtiduinal analyses in the RAMP and COPING samples. This corresponds with analytic steps 1-2 in the pre-registration for project ["Moderators of symptom trajectories of depression and anxiety during the COVID-19 pandemic"](!https://osf.io/jvca5/).

The analytic steps that will be followed for PHQ and GAD respectively are:

1. perform latent growth curve analysis of total scores across all time points to identify the best fitting trajectory for the whole sample     
2. perform growth mixture modelling to identify latent classes in trajectory that may correspond with distinct subgroups in our data

# Setup


```{r}
# clear global environment
remove(list = ls())
```


***note: some of the install and update processes require command line verification in the console. If you are running this script for the first time and it does not proceed, pen and check the console***


```{r setup, include=FALSE}

# Install / load packages

if(!require(knitr)){
  install.packages("knitr")
  library(knitr)
}

if(!require(summarytools)){
  install.packages("summarytools")
  library(summarytools)
}

if(!require(data.table)){
  install.packages("data.table")
  library(data.table)
}


if(!require(kableExtra)){
  install.packages("kableExtra")
  library(kableExtra)
}

if(!require(glue)){
  install.packages("glue")
  library(glue)
}

if(!require(MplusAutomation)){
  install.packages("MplusAutomation")
  library(MplusAutomation)
}



if(!require(texreg)){
  install.packages("texreg")
  library(texreg)
}

if(!require(relimp)){
  install.packages("relimp")
  library(relimp)
}

if(!require(BiocManager)){
  install.packages("BiocManager")
  library(BiocManager)
}

if(!require(rhdf5)){
  BiocManager::install("rhdf5")
  library(rhdf5)
}

if(!require(plyr)){
  install.packages("plyr")
  library(plyr)
}


if(!require(tidyverse)){
  install.packages("tidyverse")
  library(tidyverse)
}



## global workbook settings


knitr::opts_chunk$set(results = 'asis',      
                      comment = NA,
                      prompt = FALSE,
                      cache = FALSE, 
                      warning = FALSE,
                      echo = TRUE,
                      fig.height = 5,
                      fig.width = 10,
                      fig.align = "center")

st_options(plain.ascii = FALSE,       
            style = "rmarkdown",      
            footnote = NA,            
            subtitle.emphasis = FALSE)                         


options(scipen = 999)
```


# Colour palette

RAMP colours (first) from website and second is a generated left tetradic (rectangular) colour complement of the RAMP logo green for contrast and complement. 
```{r ieso colour palette, include=FALSE}

pres.palette <- c("#4ED1B7", "#F6C66A", "#6A6680", "#1A3E72", "#FFED04","#3F9D8A", "#FFFFFF") 

prev.pres.palette<-c("#4590B8", "#4D68D1", "#D14D68", "#D1B74D", "#68D14D", "#B74DD1", "#D1754D")

```


# Latent Growth Curves {.tabset}

Identify the best fitting latent growth curve form, i.e. that which fits all of the data best, on average, for each outcome

## PHQ9: Current Depression Symptoms Latent Growth Curve Model {.tabset}

### check number of rows missing on all variables in the dataset

```{r read in phq and check missing all cases}

phq_check <-  readRDS("../../../data_clean/phq/phq.clean_merged_total_scores.rds")

# get a list of the total score columns
total_cols <- grep("total_Wave", names(phq_check))

#count how many columns we have
n_cols <- length(total_cols)

# create a list of how many NAs are missing across these 18 columns per row
list_n_missing <- apply(phq_check[total_cols],1,function(x) sum(is.na(x)))

# count how many people are missing data for all columns (NA = total_cols)
list_all_missing <-  sum(list_n_missing ==n_cols)

print(dim(phq_check)[1])
print(list_all_missing)

```
Data set contains a total of `r print(dim(phq_check)[1])` observations. 

Number of cases missing on all variables, and thus excluded from the analyses: `r print(list_all_missing)`        

Important note: all numbers correspond exactly with MPlus output numbers (n per wave and n missing all observations etc).


### Run all models (with and without pairwise correlations)

* linear
* quadratic
* piecewise version 1: four pieces, corresponding with locdowns and easing of restrictions between April 2020 and April 2021
* piecewise version 2: three pieces, corresponding with lockdowns and easing of restrictions, but with no inflection for the March 2021 onward restriction easing as these were gradual and not as temporally well defined. 

*all of the above, but with pairwise correlations between timepoints

#### Piecewise trajectory key dates

##### trajectory 1
1. Easing of restrictions after first lockdown (23 June 2020, first wave of data collected after this is wave 6, which began on June 30th) 

  Thus piece one will be baseline - wave 5 
  capturing mental health during the first lockdown, with easing of restrictions as a potential point of change
  
2. Christmas Lockdown and lockdown 3 in England (December 20, 2020 christmas lockdown, legal third lockdown began on the 6th of January. First wave of data after the christmas shut down and new national lockdown was wave 14, which began on 19 Jan. Wave 13 began on 15 December, and most responses likely recorded before short christmas lockdown was announced)

  Thus piece two will be wave 6  - wave 13
  capturing the summer period where restrictions were relaxed and heading toward the worsening situation of December. Decmeber and January restrictions a potnetil point for change

3. Ease of restrictions begins (8 march 2021, slowly released over March. Follow up 16 began 16 March, thus captures period shortly after and into the easing)
  Thus piece 3 will be wave 14 to wave 15   
  Capturing the time during the third lockdown with stay at home orders and restrictions renewed
  Easing of restrictions a potential inflection point. 
  

Piecewise therefore: 

1. Baseline - 5
2. 6 - 13
3. 14 - 15
4. 16 - 17

##### trajectory 2

Possible that this is too compacted and had too few measurement points in shorter lockdowns to be meaningful. Thus, will also test a smaller peicewise model capturing inflections for initial lockdown, easing of restrictions, renewed lockdown into April. Arguably gradual easing of restrictionsover the course of March - July does not qualify for a probably inflection point in MH trajectories. 


Piecewise2 therefore: 

1. Baseline - 5
2. 6 - 13
3. 14 - 17

### run all models 

dont rerun models if there is already output for it (to save computational time), do show the output in the console

```{r run depression linear models}

runModels("./MPlus_input_lcga/PHQ", 
          recursive = TRUE,
          showOutput=TRUE,
          replaceOutfile="never")

#add once scripts are working
#
```


### Read model output into R

```{r read depression model}

dep.traj.all <- readModels("./MPlus_input_lcga/PHQ", 
                           recursive=TRUE)

#This also reads in the gh5 files which we use for plotting
```

### Initial checks in Mplus output files {.tabset}

- warnings  
- that none of the residual variances are negative and significant  
- loadings of indicators and intercept should all be 1, and estimates should relate to the timepoints you specified (e.g. lin 0, 1, 2; quad 0, 1, 4) 
- intercept 0 for all and correlations look sensible

#### check warnings

at the moment this doesnt say which model the warning is from, so any warning requires checking to identify its source. Though order in list will give some indication
```{r check warnings}

justWarnings <- do.call("paste",
  sapply(dep.traj.all ,"[", "warnings"))

justWarnings

```


#### check if any residual variances are negative and significant

#### Check loadings of indicators and intercept sare 1, and estimates relate to specified timepoints


#### intercept 0 for all and correlations look sensible


### Summary table of all fit indices

**To do** : The mplusautomation showsummarytable uses X11 and outputs in a separate window - if want to create one inside rmarkdown will have to do manually 

```{r Fit Indices for Depression LGC, warnings = FALSE}

showSummaryTable(dep.traj.all, keepCols=c("Title", "Observations", "Parameters", "AIC", "BIC", "CFI", "TLI", "SRMR", "RMSEA_Estimate"), sortBy="BIC") #throws error but does print!

```

#### Format Data for Plots 

Plotting the estimated means for the trajectories with adjacent residuals correlated as these all had better fit than uncorrelated models

```{r Format Depression Growth Curve Data}

dat_dep<-data.frame(matrix(nrow=11, ncol=4))

colnames(dat_dep)<-c("Observed", "Linear", "Quadratic", "Log")

dat_dep$Observed <-
  dep.traj.all$X.Users.megskelton.OneDrive...King.s.College.London.ieso_GMM.ieso_scripts.ieso_Mplus.PHQ.traj_form.ieso_phq_lgc_linear.out$gh5$means_and_variances_data$y_observed_means$values

dat_dep$Linear<-dep.traj.all$X.Users.megskelton.OneDrive...King.s.College.London.ieso_GMM.ieso_scripts.ieso_Mplus.PHQ.traj_form.ieso_phq_lgc_linear_corr.out$gh5$means_and_variances_data$y_estimated_means$values

dat_dep$Quadratic<-dep.traj.all$X.Users.megskelton.OneDrive...King.s.College.London.ieso_GMM.ieso_scripts.ieso_Mplus.PHQ.traj_form.ieso_phq_lgc_quadratic_corr.out$gh5$means_and_variances_data$y_estimated_means$values

dat_dep$Log<-dep.traj.all$X.Users.megskelton.OneDrive...King.s.College.London.ieso_GMM.ieso_scripts.ieso_Mplus.PHQ.traj_form.ieso_phq_lgc_log_corr.out$gh5$means_and_variances_data$y_estimated_means$values
dat_dep$timepoint<-c(0:10) 

dat_dep<-dat_dep%>%pivot_longer(-timepoint, names_to = "Model", values_to = "score")%>%mutate(Model = factor(Model, levels = c("Observed", "Linear", "Log", "Quadratic")))

```

#### Growth Curve Models Plot 

```{r Depression Growth Curve Forms}

ggplot() +
  geom_line(data = dat_dep,
        aes(x = timepoint, y = score, colour = Model), size = 1) +
  geom_point(data = dat_dep,
        aes(x = timepoint, y = score, colour = Model, shape=Model), show.legend = F) +
  scale_color_manual(values = pres.palette[c(4, 1:3)]) +
  labs(x = "Therapy Session", y ="PHQ9 Score") +
  scale_y_continuous(expand = c(0,0), limits = c(0,27), breaks=seq(0, 27, 3)) + 
  scale_x_continuous(expand = c(0,0), limits = c(-0.5,10.5), breaks=seq(0, 10, by = 1)) +
  theme(panel.grid.major.y = element_line(size = 0.5,
                                        linetype = 'dashed',
                                        colour = "gray"),
        axis.text = element_text(colour="black", size = 14),
        axis.title = element_text(colour="black", size = 16),
        legend.key = element_blank(),
        legend.text = element_text(colour = "black", size = 11),
        panel.background = element_blank()) 

```




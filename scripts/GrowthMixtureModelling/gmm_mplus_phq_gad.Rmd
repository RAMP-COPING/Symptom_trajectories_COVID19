---
title: "Run Latent Class Growth Analyses and Growth Mixture Modelling for RAMP longitudinal abnalyses of common mental health symptoms: GAD and PHQ"
author: "K L Purves"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
    number_sections: false
    highlight: monochrome
    theme: cerulean
code_folding: hide

html_notebook:
  theme: cerulean
toc: yes
---

This workbook centralises analyses of the PHQ-9 and GAD-7 total scores longtiduinal analyses in the RAMP and COPING samples. This corresponds with analytic steps 1-2 in the pre-registration for project ["Moderators of symptom trajectories of depression and anxiety during the COVID-19 pandemic"](!https://osf.io/jvca5/).

The analytic steps that will be followed for PHQ and GAD respectively are:

1. perform latent growth curve analysis of total scores across all time points to identify the best fitting trajectory for the whole sample     
2. perform growth mixture modelling to identify latent classes in trajectory that may correspond with distinct subgroups in our data

***Setup***


```{r}
# clear global environment
remove(list = ls())
```


***note: some of the install and update processes require command line verification in the console. If you are running this script for the first time and it does not proceed, pen and check the console***


```{r setup, include=FALSE}

# Install / load packages

if(!require(knitr)){
  install.packages("knitr")
  library(knitr)
}

if(!require(summarytools)){
  install.packages("summarytools")
  library(summarytools)
}

if(!require(data.table)){
  install.packages("data.table")
  library(data.table)
}


if(!require(kableExtra)){
  install.packages("kableExtra")
  library(kableExtra)
}

if(!require(glue)){
  install.packages("glue")
  library(glue)
}

if(!require(MplusAutomation)){
  install.packages("MplusAutomation")
  library(MplusAutomation)
}



if(!require(texreg)){
  install.packages("texreg")
  library(texreg)
}

if(!require(relimp)){
  install.packages("relimp")
  library(relimp)
}

if(!require(BiocManager)){
  install.packages("BiocManager")
  library(BiocManager)
}

if(!require(rhdf5)){
  BiocManager::install("rhdf5")
  library(rhdf5)
}

if(!require(plyr)){
  install.packages("plyr")
  library(plyr)
}


if(!require(tidyverse)){
  install.packages("tidyverse")
  library(tidyverse)
}

library(kableExtra)

## global workbook settings


knitr::opts_chunk$set(results = 'asis',      
                      comment = NA,
                      prompt = FALSE,
                      cache = FALSE, 
                      warning = FALSE,
                      echo = TRUE,
                      fig.height = 5,
                      fig.width = 10,
                      fig.align = "center")

st_options(plain.ascii = FALSE,       
            style = "rmarkdown",      
            footnote = NA,            
            subtitle.emphasis = FALSE)                         


options(scipen = 999)
```


***Colour palette***

RAMP colours (first) from website and second is a generated left tetradic (rectangular) colour complement of the RAMP logo green for contrast and complement. 
```{r ieso colour palette, include=FALSE}

pres.palette <- c("#4ED1B7", "#F6C66A", "#6A6680", "#1A3E72", "#FFED04","#3F9D8A", "#FFFFFF") 

prev.pres.palette<-c("#4590B8", "#4D68D1", "#D14D68", "#D1B74D", "#68D14D", "#B74DD1", "#D1754D")

```


# Latent Growth Curves 

Identify the best fitting latent growth curve form, i.e. that which fits all of the data best, on average, for each outcome.

Note that the MPlus inout time interval specifications go from increasing by 1 for the first  waves (we measured with two week itnervals) to increasing by 2 when we moved to monthly. The choice of interval is arbitrary, but the relative difference should be retained. 

## PHQ9: Current Depression Symptoms Latent Growth Curve Model {.tabset}

### overview of model alterations and adaptations

After manual checks of each stage, a number of alterations were needed. These are detailed here.

**low covatiance coverage**
The covariance coverage between some time points is lower than MPlus default. This prevents algortihm for missing data being applied (MLR) and standard errors cannot be computed, even when setting the coverage expectations to zero. 

Looking at our data structure and MPlus output, I suspect this is due to missing data from COPING survey for waves 2 & 3, and from the RAMP survey at wave 17 at present (due to data extraction issues which mean we do not have a recent RAMP extraction)    

Will try the following to resolve this:   

* Run without timepoints 2,3 and 17   
* This will require dropping the 4 piece trajectory model (which would only have one timepoint in the final piece) and only running the three piece version.    


In addition, I adapted the minimum coverage requirement. Default in MPlus is 0.1 Covariance coverage in MPlus refers to the amount of people who have non missing values on the pair of values. Thus, sensible minimum is sample size dependent, as there may still be a significant proportion of people who have non missing data even if that represents less than 10% of the sample in a large data set.

**update** Our lowest remaining value is 0.007 between time point 3 and timepoint 13. The lowest sample size between these is 19298 at timepoint 13. 

```{r calculate number of people with non missing}

19298*0.007

```

~40 people have data on both time points. This is low, but given LCGA (with class division) can be performed on models with as few as 30 subjects [See MPlus message board, discussion with Linda Muthen](http://www.statmodel.com/discussion/messages/23/12750.html?1592615934), this seems acceptable.

* Will drop coverage requirement to 0.0017 as this correspinds to ~30 people from our time point with the least data (18314).   


### Data summary

```{r read in phq and check missing all cases}

phq_check <-  readRDS("../../../data_clean/phq/phq.clean_merged_total_scores.rds")

# get a list of the total score columns
total_cols <- grep("total_Wave", names(phq_check))

#count how many columns we have
n_cols <- length(total_cols)

# create a list of how many NAs are missing across these 18 columns per row
list_n_missing <- apply(phq_check[total_cols],1,function(x) sum(is.na(x)))

# count how many people are missing data for all columns (NA = total_cols)
list_all_missing <-  sum(list_n_missing ==n_cols)

print(dim(phq_check)[1])
print(list_all_missing)

```


Important note: all numbers correspond exactly with MPlus output numbers (n per wave and n missing all observations etc).
  
   
### Summary of models run

* linear
* quadratic
* piecewise version 1: four pieces, corresponding with locdowns and easing of restrictions between April 2020 and April 2021
* piecewise version 2: three pieces, corresponding with lockdowns and easing of restrictions, but with no inflection for the March 2021 onward restriction easing as these were gradual and not as temporally well defined. 

*all of the above, but with pairwise correlations between timepoints

When dropping timepoints 1,2 and 17 (first two follow ups before COPING had started data collection and last follow up where we currednlty dont have RAMP data extracted) I only run the 3 piece model, as a model with only two data points, both of which fall in a vaguely defined period of the pandemic no longer makes sense.


#### Piecewise trajectory key dates

##### trajectory 1
1. Easing of restrictions after first lockdown (23 June 2020, first wave of data collected after this is wave 6, which began on June 30th) 

  Thus piece one will be baseline - wave 5 
  capturing mental health during the first lockdown, with easing of restrictions as a potential point of change
  
2. Christmas Lockdown and lockdown 3 in England (December 20, 2020 christmas lockdown, legal third lockdown began on the 6th of January. First wave of data after the christmas shut down and new national lockdown was wave 14, which began on 19 Jan. Wave 13 began on 15 December, and most responses likely recorded before short christmas lockdown was announced)

  Thus piece two will be wave 6  - wave 13
  capturing the summer period where restrictions were relaxed and heading toward the worsening situation of December. Decmeber and January restrictions a potnetil point for change

3. Ease of restrictions begins (8 march 2021, slowly released over March. Follow up 16 began 16 March, thus captures period shortly after and into the easing)
  Thus piece 3 will be wave 14 to wave 15   
  Capturing the time during the third lockdown with stay at home orders and restrictions renewed
  Easing of restrictions a potential inflection point. 
  

Piecewise therefore: 

1. Baseline - 5
2. 6 - 13
3. 14 - 15
4. 16 - 17

##### trajectory 2

Possible that this is too compacted and had too few measurement points in shorter lockdowns to be meaningful. Thus, will also test a smaller peicewise model capturing inflections for initial lockdown, easing of restrictions, renewed lockdown into April. Arguably gradual easing of restrictionsover the course of March - July does not qualify for a probably inflection point in MH trajectories. 


Piecewise2 therefore: 

1. Baseline - 5
2. 6 - 13
3. 14 - 17

#### run all models 

dont rerun models if there is already output for it (to save computational time), do show the output in the console

```{r run depression linear models}

runModels("./MPlus_input_lcga/PHQ", 
          recursive = FALSE,
          showOutput=TRUE,
          replaceOutfile="never")

```

### Examine model output {.tabset}
this reads in all output, including the gh5 plot files
```{r read depression model}

dep.traj.all <- readModels("./MPlus_input_lcga/PHQ", 
                           recursive=FALSE)

```


#### Check key indicators of model stability {.tabset}

- warnings  
- that none of the residual variances are negative and significant  
- loadings of indicators and intercept should all be 1, and estimates should relate to the time points you specified (e.g. lin 0, 1, 2; quad 0, 1, 4) 
- intercept 0 for all and correlations look sensible

##### warnings

at the moment this doesnt say which model the warning is from, so any warning requires checking to identify its source. Though order in list will give some indication
```{r check warnings}

justWarnings <- do.call("paste",
  sapply(dep.traj.all ,"[", "warnings"))

justWarnings

```

Warnings are all about missing data (missing on all obs, this number lines up with our expectations from the dataset in the section above) 


Otherwise, no warnings. Check one complete.

Note that there are more people missing on all observations having dropped time points 2,3, and 17. Was 7866, but this version is 8217 .


##### errors

Check any errors with running any of the models. Oytput here will not say whicu model it belongs to, so will need to manually examine if errors occur,

```{r check errors}

justErrors <- do.call("paste",
  sapply(dep.traj.all ,"[", "errors"))

justErrors

```

###### Issue 1: Models fail to finish running and converge (resolved)

Some of the models have failed to converge:    

* Piecwise with pairwise residual correlations    
* Quadratic   
* Quadratic with pariwise residual correlations


Steps:    
* Increased number of iterations to 5000 (Mplus default is 1000).    
* This worked somwhat for the piecewise and quadratic (without pairwise correlations) which now have more informative errors    
* This did not work at all for quadratic (with pairwise residual correlation). Increased iterations to 10000 for this one.    
* This worked.    


###### Issue 2: Models are no specified due to time point 3 parameter (resolved)

Now all three run, but could not compute standard errors as the models were misidentified or did not converge.

Issues are all with specified parameters now:

***quadratic***: Problem involving parameter 2 (T_3)
*   examining the data, I have made an error with the dataset. There are 4325 in this time point. This corresponds to the second follow up that is meant to be dropped from this datafile. Interestingly, T4 onwards is correct. T3 should have 2662 observations. Appears I have  wrongly dropped this wave instead of follow up 2. *Note: this is exactly what I had done. Corrected and rerun all models*

###### Issue 3: Models are no specified due to low coverage covariacne between t 3 and timepoint 6,8,16 (resolved. CHECK WITh KATIE)

Checked this manually, and there are only 4 people who did both timepoint 3 and timepoint 6, 4 who did timepoint 3 and tomepoint 8, and only 3 who did time point 3 and timepoint 16

* issues to consider here include the fact that having low observed data can caus instability and may lead to ore groups than there really are at a later stage   
* On the other hand, the fixed dataset now has good coverage for all other pairings ( min 0.007, representing > 100 people in all cases). Thus dropping this time point might lose more information than it gains.

Options are either dropping time point 3, or dropping coverage requirement.

* tried dropping coverage requirement to see if there remained problems with parameter 3 that would indicate instability.

###### Issue 4: Quadratic models misspecifed

The two quadratic models are not converging. Without pairwise correlations the parameter MPlus flags is the intercept. With pairwise correlation it flags the correlations between time points 15 and 16

* Checked the quadratic output for intercept and noticed some very high variances. I thus specified the model allowing the intercept variance to be freed instead of constrained
* Increasing the number of start value attempts from default 10 2 to 50 5 (50 initial stage starts, 5 final stage optimisations), then 500 initial starts **did not work**
* Fixing the intercept to 0,40 (variance) 7 (mean) **did not work**





##### check if any residual variances are negative and significant

###### Linear 
```{r check if residual variances negative lin}

model <- dep.traj.all$phq_latentGrowthCurve_linear.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```

###### Linear with pairwise correlations
```{r check if residual variances negative lin pairwise}

model <- dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```

###### Quadratic 
```{r check if residual variances negative quad}

model <- dep.traj.all$phq_latentGrowthCurve_quadratic.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```

###### Quadratic with pairwise correlations
```{r check if residual variances negative quad pairwise}

model <- dep.traj.all$phq_latentGrowthCurve_quadratic_withPairwiseCorrelations.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```

###### Piecewise 1 (IGNORE)
```{r check if residual variances negative piece 1, eval=FALSE}

# model <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version1_4pieces.out$parameters$unstandardized
# model[model$paramHeader == "Residual.Variances",]

```

###### Piecewise 1 with pairwise correlations (IGNORE)
```{r check if residual variances negative piece 1 pairwise, eval=FALSE}

# model <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version1_4pieces_wPairwise_correlations.out$parameters$unstandardized
# model[model$paramHeader == "Residual.Variances",]

```


###### Piecewise 2
```{r check if residual variances negative piece 2}

model <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```

###### Piecewise 2 with pairwise correlations
```{r check if residual variances negative piece 2 pairwise}

model <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$parameters$unstandardized
model[model$paramHeader == "Residual.Variances",]

```
##### summary

All models meet this check criteria

#### Detailed output for each model {.tabset}

***Check:***    
1. loadings of indicators and intercepts are 1    
2. Estimates relate to specified timepoints   
3. intercept 0 for all     
4. correlations look sensible      

Print output file for each correlation for examination of these details and any other relevant information

##### Linear 
1. loadings of indicators and intercepts are 1   
***YES***
2. Estimates relate to specified timepoints  
***YES***


```{r check full output negative lin}

dep.traj.all$phq_latentGrowthCurve_linear.out$output[277:311]

```
3. intercept 0 for all  
***YES***

```{r check intercepts are zero lin}

dep.traj.all$phq_latentGrowthCurve_linear.out$output[319:337]
```
4. correlations look sensible  
***yes***
```{r check correlations lin}

dep.traj.all$phq_latentGrowthCurve_linear.out$output[598:642]
```

##### Linear (with pairwise correlations between time points)

1. loadings of indicators and intercepts are 1   
***YES***
2. Estimates relate to specified timepoints  
***YES***

```{r check full output negative lin pairwise}

dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$output[277:311]

```
3. intercept 0 for all  
***YES***

```{r check intercepts are zero lin pairwise}

dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$output[365:380]
```
4. correlations look sensible  
***yes***
```{r check correlations lin pairwise}

dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$output[685:727]
```

##### Quadratic

1. loadings of indicators and intercepts are 1   
***WAS NOT SPECIFIED**
2. Estimates relate to specified timepoints  
***WAS NOT SPECIFIED***
```{r check full output negative quad}

dep.traj.all$phq_latentGrowthCurve_quadratic.out$output[277:311]

```
3. intercept 0 for all  
***WAS NOT SPECIFIED***

```{r check intercepts are zero quad}

dep.traj.all$phq_latentGrowthCurve_quadratic.out$output[319:337]
```
4. correlations look sensible  
***WAS NOT SPECIFIED***
```{r check correlations quad}

dep.traj.all$phq_latentGrowthCurve_quadratic.out$output[598:642]
```

##### Quadratic with pairwise correlations

1. loadings of indicators and intercepts are 1  
***WAS NOT SPECIFIED***
2. Estimates relate to specified timepoints  
***WAS NOT SPECIFIED***
```{r check full output negative quad pairwise}

dep.traj.all$phq_latentGrowthCurve_quadratic_withPairwiseCorrelations.out$output[277:311]

```
3. intercept 0 for all  
***WAS NOT SPECIFIED***

```{r check intercepts are zero quad pairwise}

dep.traj.all$phq_latentGrowthCurve_quadratic_withPairwiseCorrelations.out$output[319:337]
```
4. correlations look sensible  
***WAS NOT SPECIFIED***
```{r check correlations quad pairwise}

dep.traj.all$phq_latentGrowthCurve_quadratic_withPairwiseCorrelations.out$output[598:642]
```


##### Piecewise (3 pieces)

1. loadings of indicators and intercepts are 1  
***YES***
2. Estimates relate to specified timepoints  
**YES**
```{r check full output negative 3piece}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces.out$output[308:377]

```
3. intercept 0 for all  
***YES***

```{r check intercepts are zero 3piece}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces.out$output[532:552]
```
4. correlations look sensible  
***yes***
```{r check correlations 3piece}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces.out$output[723:766]
```


##### Piecewise (3 pieces) with pairwise correlations
1. loadings of indicators and intercepts are 1  
***YES***
2. Estimates relate to specified timepoints  
***YES***
```{r check full output negative 3piece pairwise}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$output[312:380]

```
3. intercept 0 for all  
***YES***

```{r check intercepts are zero 3piece pairwise}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$output[442:464]
```
4. correlations look sensible  
***yes***
```{r check correlations 3piece pairwise}

dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$output[811:854]
```
##### Summary

All meet these criteria

### Summary table of all fit indices

Sorted by BIC, as this is the most informative criteria (as per Muthens)

throws error but does print
```{r Fit Indices for Depression LGC, warnings = FALSE}

showSummaryTable(dep.traj.all, keepCols=c("Title", "Observations", "Parameters", "AIC", "BIC", "CFI", "TLI", "SRMR", "RMSEA_Estimate"), sortBy="BIC",)

```


### Plot {.tabset}

I show the plots for all runs that worked. Output for all runs is available in the GMM folder on GitHub to review input and output data that generated these plots. The main analytic sections above will only refer to the final model run. 

#### Timepoints where both studies have data

##### Format Data for Plots 

Plotting the estimated means for the trajectories with adjacent residuals correlated as these all had better fit than uncorrelated models

```{r Format Depression Growth Curve Data run 2}

dat_dep_run_2<-data.frame(matrix(nrow=15, ncol=4))

colnames(dat_dep_run_2)<-c("Linear", "LinearWithCorrelations",  "Piecewise", "PiecewiseWithCorrelations")


dat_dep_run_2$Linear <-dep.traj.all$phq_latentGrowthCurve_linear.out$gh5$means_and_variances_data$y_estimated_means$values
dat_dep_run_2$LinearWithCorrelations <- dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values

dat_dep_run_2$Piecewise <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces.out$gh5$means_and_variances_data$y_estimated_means$values

dat_dep_run_2$PiecewiseWithCorrelations <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values


dat_dep_run_2$timepoint<-c(0:14) 

dat_dep_run_2<-dat_dep_run_2%>%pivot_longer(-timepoint, names_to = "Model", values_to = "score")%>%mutate(Model = factor(Model, levels = c("Linear", "LinearWithCorrelations",  "Piecewise", "PiecewiseWithCorrelations")))

```

##### Growth Curve Plot 

```{r Depression Growth Curve Forms run 2}

growth_curves_run2 <- ggplot() +
  geom_line(data = dat_dep_run_2,
        aes(x = timepoint, y = score, colour = Model), size = 1) +
  geom_point(data = dat_dep_run_2,
        aes(x = timepoint, y = score, colour = Model, shape=Model), show.legend = F) +
  scale_color_manual(values = pres.palette[c(4, 1:3)]) +
  labs(x = "Follow up time point", y ="PHQ9 Score") +
  scale_y_continuous(expand = c(0,0), limits = c(6,10), breaks=seq(6, 10, 3)) + 
  scale_x_continuous(expand = c(0,0), limits = c(-0.5,14.5), breaks=seq(0, 14, by = 1)) +
  theme(panel.grid.major.y = element_line(size = 0.5,
                                        linetype = 'dashed',
                                        colour = "gray"),
        axis.text = element_text(colour="black", size = 14),
        axis.title = element_text(colour="black", size = 16),
        legend.key = element_blank(),
        legend.text = element_text(colour = "black", size = 11),
        panel.background = element_blank()) 

growth_curves_run2

```


#### Only pairwise correlations
As these make most theoretical sense and show better mode fit, show the trajectories onluy including residual correlations between adjacent time points to make it easier to compare the models


```{r Format Depression Growth Curve Data run 2b}

dat_dep_run_2b<-data.frame(matrix(nrow=15, ncol=2))

colnames(dat_dep_run_2b)<-c("Linear",  "Piecewise")


dat_dep_run_2b$Linear <- dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values
dat_dep_run_2b$Piecewise <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values


dat_dep_run_2b$timepoint<-c(0:14) 

dat_dep_run_2b<-dat_dep_run_2b%>%pivot_longer(-timepoint, names_to = "Model", values_to = "score")%>%mutate(Model = factor(Model, levels = c("Linear", "Piecewise")))
```






##### Growth Curve Plot 

```{r Depression Growth Curve Forms run 2b}
growth_curves_run2b <- ggplot() +
  geom_line(data = dat_dep_run_2b,
        aes(x = timepoint, y = score, colour = Model), size = 1) +
  geom_point(data = dat_dep_run_2b,
        aes(x = timepoint, y = score, colour = Model, shape=Model), show.legend = F) +
  scale_color_manual(values = prev.pres.palette[c(4, 1:3)]) +
  labs(x = "Follow up time point", y ="PHQ9 Score") +
  scale_y_continuous(expand = c(0,0), limits = c(6,10), breaks=seq(6, 10, 3)) + 
  scale_x_continuous(expand = c(0,0), limits = c(-0.5,14.5), breaks=seq(0, 14, by = 1)) +
  theme(panel.grid.major.y = element_line(size = 0.5,
                                        linetype = 'dashed',
                                        colour = "gray"),
        axis.text = element_text(colour="black", size = 14),
        axis.title = element_text(colour="black", size = 16),
        legend.key = element_blank(),
        legend.text = element_text(colour = "black", size = 11),
        panel.background = element_blank()) 

growth_curves_run2b



```

#### Observed and estimated means
lot pairwise correlation versions only. Plot estimated means from model alongside the observed means from the data.



```{r Format Depression Growth Curve Data run 2 obs est}

dat_dep_run_2c<-data.frame(matrix(nrow=15, ncol=3))

colnames(dat_dep_run_2c)<-c("Linear","Piecewise", "Observed")


dat_dep_run_2c$Linear <- dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values
dat_dep_run_2c$Piecewise <- dep.traj.all$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values
dat_dep_run_2c$Observed <- dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$gh5$means_and_variances_data$y_observed_means$values

dat_dep_run_2c$timepoint<-c(0:14) 

dat_dep_run_2c<-dat_dep_run_2c%>%pivot_longer(-timepoint, names_to = "Model", values_to = "score")%>%mutate(Model = factor(Model, levels = c("Linear", "Piecewise", "Observed")))


dat_dep_run_2c <- dat_dep_run_2c %>%
  mutate(Type = case_when(Model == "Observed"~ "Observed",
                          TRUE ~ "Estimated"))
  
```






##### Growth Curve Plot 

```{r Depression Growth Curve Forms run 2 obs est}
growth_curves_run2c <- ggplot() +
  geom_line(data = dat_dep_run_2c,
        aes(x = timepoint, y = score, colour = Model,linetype=Type)) +
  geom_point(data = dat_dep_run_2c,
        aes(x = timepoint, y = score, colour = Model, shape=Model), show.legend = F) +
  scale_color_manual(values = pres.palette[c(4, 1:3)]) +
  labs(x = "Follow up time point", y ="PHQ9 Score") +
  scale_y_continuous(expand = c(0,0), limits = c(6,10), breaks=seq(6, 10, 3)) + 
  scale_x_continuous(expand = c(0,0), limits = c(-0.5,14.5), breaks=seq(0, 14, by = 1)) +
  theme(panel.grid.major.y = element_line(size = 0.5,
                                        linetype = 'dashed',
                                        colour = "gray"),
        axis.text = element_text(colour="black", size = 14),
        axis.title = element_text(colour="black", size = 16),
        legend.key = element_blank(),
        legend.text = element_text(colour = "black", size = 11),
        panel.background = element_blank()) 

growth_curves_run2c



```

#### Run 1: all time points

##### Format Data for Plots 

Plotting the estimated means for the trajectories with adjacent residuals correlated as these all had better fit than uncorrelated models

```{r Format Depression Growth Curve Data}

dep.traj.run.1 <- readModels("./MPlus_input_lcga/PHQ/Output_Run1_alltimepoints", 
                           recursive=TRUE)


dat_dep_run_1<-data.frame(matrix(nrow=18, ncol=3))

colnames(dat_dep_run_1)<-c("Linear", "Quadratic",  "Piecewise3")

#  "LinearCor", "QuadraticCor","Piecewise4", "Piecewise4Cor",, "Piecewise3Cor"

dat_dep_run_1$Linear <-dep.traj.run.1$..MPlus_input_lcga.PHQ.Output_Run1_alltimepoints.phq_latentGrowthCurve_linear.out$gh5$means_and_variances_data$y_estimated_means$values

#dat_dep_run_1$LinearCor<-dep.traj.all$phq_latentGrowthCurve_linear_withpairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values

dat_dep_run_1$Quadratic<-dep.traj.run.1$..MPlus_input_lcga.PHQ.Output_Run1_alltimepoints.phq_latentGrowthCurve_quadratic.out$gh5$means_and_variances_data$y_estimated_means$values

#dat_dep_run_1$QuadraticCor<-dep.traj.run.1$phq_latentGrowthCurve_quadratic_withPairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values

#dat_dep_run_1$Piecewise4<-dep.traj.run.1$phq_latentGrowthCurve_piecwewise_version1_4pieces.out$gh5$means_and_variances_data$y_estimated_means$values

#dat_dep_run_1$Piecewise4Cor<-dep.traj.run.1$phq_latentGrowthCurve_piecwewise_version1_4pieces_wPairwise_correlations.out$gh5$means_and_variances_data$y_estimated_means$values


dat_dep_run_1$Piecewise3<-dep.traj.run.1$..MPlus_input_lcga.PHQ.Output_Run1_alltimepoints.phq_latentGrowthCurve_piecwewise_version2_3pieces.out$gh5$means_and_variances_data$y_estimated_means$values

#dat_dep_run_1$Piecewise3Cor<-dep.traj.run.1$phq_latentGrowthCurve_piecwewise_version2_3pieces_wPairwiseCorrelations.out$gh5$means_and_variances_data$y_estimated_means$values


dat_dep_run_1$timepoint<-c(0:17) 

dat_dep_run_1<-dat_dep_run_1%>%pivot_longer(-timepoint, names_to = "Model", values_to = "score")%>%mutate(Model = factor(Model, levels = c("Linear","Quadratic","Piecewise3")))

```

##### Growth Curve Plot 

```{r Depression Growth Curve Forms}

growth_curves_run1 <- ggplot() +
  geom_line(data = dat_dep_run_1,
        aes(x = timepoint, y = score, colour = Model), size = 1) +
  geom_point(data = dat_dep_run_1,
        aes(x = timepoint, y = score, colour = Model, shape=Model), show.legend = F) +
  scale_color_manual(values = pres.palette[c(4, 1:3)]) +
  labs(x = "Follow up time point", y ="PHQ9 Score") +
  scale_y_continuous(expand = c(0,0), limits = c(6,10), breaks=seq(6, 10, 3)) + 
  scale_x_continuous(expand = c(0,0), limits = c(-0.5,18.5), breaks=seq(0, 18, by = 1)) +
  theme(panel.grid.major.y = element_line(size = 0.5,
                                        linetype = 'dashed',
                                        colour = "gray"),
        axis.text = element_text(colour="black", size = 14),
        axis.title = element_text(colour="black", size = 16),
        legend.key = element_blank(),
        legend.text = element_text(colour = "black", size = 11),
        panel.background = element_blank()) 

growth_curves_run1


```



